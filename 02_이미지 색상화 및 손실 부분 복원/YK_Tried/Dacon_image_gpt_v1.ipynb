{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sR1FsXesC5d5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "BASE_DIR = '/content/drive/MyDrive/open/'\n",
        "\n",
        "# 데이터 경로 설정\n",
        "TRAIN_INPUT_PATH = os.path.join(BASE_DIR, 'train_input')\n",
        "TRAIN_GT_PATH = os.path.join(BASE_DIR, 'train_gt')\n",
        "TEST_INPUT_PATH = os.path.join(BASE_DIR, 'test_input')"
      ],
      "metadata": {
        "id": "o8C8vvLoDgMU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# 데이터 로드 함수\n",
        "def load_images(input_path, gt_path=None):\n",
        "    input_images = []\n",
        "    gt_images = []\n",
        "\n",
        "    for filename in tqdm(os.listdir(input_path)):\n",
        "        input_img = cv2.imread(os.path.join(input_path, filename), cv2.IMREAD_COLOR)\n",
        "        input_img = cv2.resize(input_img, (256, 256)) / 255.0\n",
        "        input_images.append(input_img)\n",
        "\n",
        "        if gt_path:\n",
        "            gt_img = cv2.imread(os.path.join(gt_path, filename), cv2.IMREAD_COLOR)\n",
        "            gt_img = cv2.resize(gt_img, (256, 256)) / 255.0\n",
        "            gt_images.append(gt_img)\n",
        "\n",
        "    if gt_path:\n",
        "        return np.array(input_images), np.array(gt_images)\n",
        "    return np.array(input_images)"
      ],
      "metadata": {
        "id": "TdrQu6F3IXdW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 데이터 로드\n",
        "train_inputs, train_gts = load_images(TRAIN_INPUT_PATH, TRAIN_GT_PATH)\n",
        "test_inputs = load_images(TEST_INPUT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv1BPrE_IXgJ",
        "outputId": "155151f7-00c5-4c0b-8ebb-6941a747c2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 297/29603 [00:29<24:40, 19.80it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 데이터를 학습에 사용\n",
        "x_train, y_train = train_inputs, train_gts\n",
        "\n",
        "# 학습 데이터 크기 확인\n",
        "print(\"Train data shape:\", x_train.shape, y_train.shape)"
      ],
      "metadata": {
        "id": "5hGs97gIEA2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNet 모델 정의\n",
        "def build_unet(input_shape=(256, 256, 3)):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Contracting Path\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Expanding Path\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = Concatenate()([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = Concatenate()([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = Concatenate()([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = Concatenate()([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    return Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "WKuoozpDEDn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "model = build_unet()\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n"
      ],
      "metadata": {
        "id": "uYykilCzETZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=2,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "id": "KeVMxC1WEU4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 완료 후 모델 저장\n",
        "model.save('image_restoration_model_v1.h5')"
      ],
      "metadata": {
        "id": "WlqOJaAEFQE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 및 평가\n",
        "preds = model.predict(test_inputs)"
      ],
      "metadata": {
        "id": "ko5W5RYOFNOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ssim_score(true, pred):\n",
        "    # 전체 RGB 이미지를 사용해 SSIM 계산 (channel_axis=-1)\n",
        "    ssim_value = ssim(true, pred, channel_axis=-1, data_range=pred.max() - pred.min())\n",
        "    return ssim_value\n",
        "\n",
        "def masked_ssim_score(true, pred, mask):\n",
        "    # 손실 영역의 좌표에서만 RGB 채널별 픽셀 값 추출\n",
        "    true_masked_pixels = true[mask > 0]\n",
        "    pred_masked_pixels = pred[mask > 0]\n",
        "\n",
        "    # 손실 영역 픽셀만으로 SSIM 계산 (채널축 사용)\n",
        "    ssim_value = ssim(\n",
        "        true_masked_pixels,\n",
        "        pred_masked_pixels,\n",
        "        channel_axis=-1,\n",
        "        data_range=pred.max() - pred.min()\n",
        "    )\n",
        "    return ssim_value\n",
        "\n",
        "def histogram_similarity(true, pred):\n",
        "    # BGR 이미지를 HSV로 변환\n",
        "    true_hsv = cv2.cvtColor(true, cv2.COLOR_BGR2HSV)\n",
        "    pred_hsv = cv2.cvtColor(pred, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # H 채널에서 히스토그램 계산 및 정규화\n",
        "    hist_true = cv2.calcHist([true_hsv], [0], None, [180], [0, 180])\n",
        "    hist_pred = cv2.calcHist([pred_hsv], [0], None, [180], [0, 180])\n",
        "    hist_true = cv2.normalize(hist_true, hist_true).flatten()\n",
        "    hist_pred = cv2.normalize(hist_pred, hist_pred).flatten()\n",
        "\n",
        "    # 히스토그램 간 유사도 계산 (상관 계수 사용)\n",
        "    similarity = cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_CORREL)\n",
        "    return similarity\n"
      ],
      "metadata": {
        "id": "sbIjU9odEkK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 메트릭스 계산 함수\n",
        "def evaluate_model(true_images, pred_images):\n",
        "    ssim_scores = []\n",
        "    masked_ssim_scores = []\n",
        "    hist_similarities = []\n",
        "\n",
        "    for true, pred in zip(true_images, pred_images):\n",
        "        # 손실 영역의 마스크 생성 (흑백 이미지에서 특정 조건으로 생성)\n",
        "        mask = (true == 0).astype(np.uint8)  # 예: 손실된 영역이 0으로 채워진 경우\n",
        "\n",
        "        # 전체 SSIM 계산\n",
        "        ssim_scores.append(ssim_score(true, pred))\n",
        "\n",
        "        # 손실 영역에서만 SSIM 계산\n",
        "        masked_ssim_scores.append(masked_ssim_score(true, pred, mask))\n",
        "\n",
        "        # 히스토그램 유사도 계산\n",
        "        hist_similarities.append(histogram_similarity(true, pred))\n",
        "\n",
        "    # 평균 점수를 반환\n",
        "    return {\n",
        "        \"SSIM\": np.mean(ssim_scores),\n",
        "        \"Masked SSIM\": np.mean(masked_ssim_scores),\n",
        "        \"Histogram Similarity\": np.mean(hist_similarities),\n",
        "    }\n",
        "\n",
        "# 모델 학습 후 테스트 데이터 예측\n",
        "# preds = model.predict(test_inputs)\n",
        "\n",
        "# 성능 평가 실행\n",
        "results = evaluate_model(test_inputs, preds)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Evaluation Results:\", results)\n"
      ],
      "metadata": {
        "id": "SB3i8TjPEYYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출 파일 생성\n",
        "import zipfile\n",
        "SUBMISSION_DIR = os.path.join(BASE_DIR, 'submission')\n",
        "\n",
        "submission_file = os.path.join(BASE_DIR, 'sample_submission.zip')\n",
        "with zipfile.ZipFile(submission_file, 'w') as zipf:\n",
        "    for filename in os.listdir(SUBMISSION_DIR):\n",
        "        filepath = os.path.join(SUBMISSION_DIR, filename)\n",
        "        zipf.write(filepath, arcname=filename)\n",
        "\n",
        "print(f\"Submission file saved at {submission_file}\")"
      ],
      "metadata": {
        "id": "RvRrAxcBF7MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DRjOky3uGf7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}